{
 "metadata": {
  "name": "CPUPredictV1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as pl\nimport sklearn\nfrom sknn.mlp import Regressor, Layer\nimport pickle\nfrom sknn.platform import cpu64",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": "WARNING:sknn:Theano was already imported and cannot be reconfigured.\n"
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "raw_data = pd.read_csv(\"/home/nhuan/MyWorking/tpds-2012-workload.csv\");\nnn = Regressor(\n    layers=[\n        Layer(\"Rectifier\", units=10),\n        Layer(\"Linear\")],\n    learning_rate=0.02,\n    n_iter=30)\nn_row = raw_data.icol(1).count()\nn_input = 11\nn_range = 57800",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "X_training = np.asarray([[raw_data.ix[t-i][4] for i in range(1,n_input)]\n             for t in np.arange(n_input-1,n_range+5)])\ny_training = np.asarray([raw_data.ix[t][4] for t in np.arange(n_input-1,n_range+5)])\nnn.fit(X_training,y_training)\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": "Regressor(batch_size=1, debug=False, dropout_rate=None, f_stable=0.001,\n     hidden0=<sknn.nn.Layer `Rectifier`: name=u'hidden0', units=10>,\n     layers=[<sknn.nn.Layer `Rectifier`: name=u'hidden0', units=10>, <sknn.nn.Layer `Linear`: name=u'output', units=1>],\n     learning_momentum=0.9, learning_rate=0.02, learning_rule=u'sgd',\n     loss_type=u'mse', mutator=None, n_iter=30, n_stable=50,\n     output=<sknn.nn.Layer `Linear`: name=u'output', units=1>,\n     random_state=None, regularize=None, valid_set=None, valid_size=0.0,\n     verbose=None, weight_decay=None)"
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "n_sample2 = np.asarray([[raw_data.ix[t-i][4] for i in range(1,n_input)] for t in np.arange (289*400,289*410)])\nn_test2 =  np.asarray([raw_data.ix[t][4] for t in np.arange(289*400+1,289*410+1)])\nnn.score(n_sample2,n_test2)\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": "0.1645784429433288"
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "pred = np.asarray(nn.predict(n_sample2))\nax = pl.subplot()\nax.set_color_cycle(['blue','red'])\npl.plot(n_test2)\npl.plot(pred)\npl.show()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "pd.DataFrame(zip(pred,n_test2),columns=[\"Prediction\",\"Real\"])",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prediction</th>\n      <th>Real</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0 </th>\n      <td> [0.0362867376903]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>1 </th>\n      <td> [0.0447627411036]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>2 </th>\n      <td> [0.0510876259838]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>3 </th>\n      <td> [0.0491255159444]</td>\n      <td> 0.00</td>\n    </tr>\n    <tr>\n      <th>4 </th>\n      <td> [0.0500659983257]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>5 </th>\n      <td> [0.0450002643388]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>6 </th>\n      <td> [0.0321995770502]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>7 </th>\n      <td>  [0.031017211101]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>8 </th>\n      <td> [0.0377626088965]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>9 </th>\n      <td> [0.0513074151969]</td>\n      <td> 0.02</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td> [0.0529344098925]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td> [0.0415945603037]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>  [0.034360319904]</td>\n      <td> 0.11</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td> [0.0363864928462]</td>\n      <td> 0.09</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td> [0.0499070328419]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td> [0.0613323597268]</td>\n      <td> 0.05</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td> [0.0651835191488]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td> [0.0619238545694]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td> [0.0550607244366]</td>\n      <td> 0.09</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td> [0.0485799282737]</td>\n      <td> 0.09</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td> [0.0565420488472]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td> [0.0693067509215]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td> [0.0698723776744]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td> [0.0619542915795]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td> [0.0595793913997]</td>\n      <td> 0.13</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td> [0.0602029237462]</td>\n      <td> 0.05</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>   [0.07022474703]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>  [0.071410743139]</td>\n      <td> 0.15</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td> [0.0660216569946]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td> [0.0781061908612]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td> [0.0757276134319]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td> [0.0667325505796]</td>\n      <td> 0.64</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td> [0.0717997229909]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>  [0.119594992888]</td>\n      <td> 0.09</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td> [0.0999002626874]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>  [0.133010814484]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td> [0.0885031270008]</td>\n      <td> 0.05</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td> [0.0819767843867]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td> [0.0855492304298]</td>\n      <td> 0.09</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td> [0.0968965106546]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>  [0.120365773377]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>  [0.115911484107]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td> [0.0845359471257]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td> [0.0612724900847]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td> [0.0592738230714]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td> [0.0537799940785]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td> [0.0566042015648]</td>\n      <td> 0.12</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td> [0.0575897295986]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td> [0.0658825378883]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td> [0.0686546517795]</td>\n      <td> 0.08</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td> [0.0670963421191]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td> [0.0703818173322]</td>\n      <td> 0.04</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td> [0.0676256649902]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td> [0.0598914916462]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td> [0.0585947230514]</td>\n      <td> 0.09</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td> [0.0638408933839]</td>\n      <td> 0.05</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td> [0.0699993938532]</td>\n      <td> 0.07</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td> [0.0661385728627]</td>\n      <td> 0.05</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td> [0.0637450200707]</td>\n      <td> 0.06</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td> [0.0599939562494]</td>\n      <td> 0.11</td>\n    </tr>\n    <tr>\n      <th></th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2890 rows \u00d7 2 columns</p>\n</div>",
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": "           Prediction  Real\n0   [0.0362867376903]  0.08\n1   [0.0447627411036]  0.06\n2   [0.0510876259838]  0.04\n3   [0.0491255159444]  0.00\n4   [0.0500659983257]  0.04\n5   [0.0450002643388]  0.04\n6   [0.0321995770502]  0.06\n7    [0.031017211101]  0.08\n8   [0.0377626088965]  0.06\n9   [0.0513074151969]  0.02\n10  [0.0529344098925]  0.04\n11  [0.0415945603037]  0.06\n12   [0.034360319904]  0.11\n13  [0.0363864928462]  0.09\n14  [0.0499070328419]  0.07\n15  [0.0613323597268]  0.05\n16  [0.0651835191488]  0.06\n17  [0.0619238545694]  0.04\n18  [0.0550607244366]  0.09\n19  [0.0485799282737]  0.09\n20  [0.0565420488472]  0.06\n21  [0.0693067509215]  0.04\n22  [0.0698723776744]  0.08\n23  [0.0619542915795]  0.08\n24  [0.0595793913997]  0.13\n25  [0.0602029237462]  0.05\n26    [0.07022474703]  0.04\n27   [0.071410743139]  0.15\n28  [0.0660216569946]  0.08\n29  [0.0781061908612]  0.04\n30  [0.0757276134319]  0.07\n31  [0.0667325505796]  0.64\n32  [0.0717997229909]  0.07\n33   [0.119594992888]  0.09\n34  [0.0999002626874]  0.06\n35   [0.133010814484]  0.04\n36  [0.0885031270008]  0.05\n37  [0.0819767843867]  0.07\n38  [0.0855492304298]  0.09\n39  [0.0968965106546]  0.07\n40   [0.120365773377]  0.06\n41   [0.115911484107]  0.06\n42  [0.0845359471257]  0.08\n43  [0.0612724900847]  0.04\n44  [0.0592738230714]  0.07\n45  [0.0537799940785]  0.04\n46  [0.0566042015648]  0.12\n47  [0.0575897295986]  0.08\n48  [0.0658825378883]  0.08\n49  [0.0686546517795]  0.08\n50  [0.0670963421191]  0.07\n51  [0.0703818173322]  0.04\n52  [0.0676256649902]  0.06\n53  [0.0598914916462]  0.07\n54  [0.0585947230514]  0.09\n55  [0.0638408933839]  0.05\n56  [0.0699993938532]  0.07\n57  [0.0661385728627]  0.05\n58  [0.0637450200707]  0.06\n59  [0.0599939562494]  0.11\n                  ...   ...\n\n[2890 rows x 2 columns]"
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}